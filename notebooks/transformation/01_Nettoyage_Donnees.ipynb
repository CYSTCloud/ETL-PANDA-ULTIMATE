{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation des données de pandémies - Partie 1: Nettoyage\n",
    "\n",
    "Ce notebook réalise le nettoyage des données extraites pour les préparer à la transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration initiale\n",
    "\n",
    "Importation des bibliothèques nécessaires et chargement des données extraites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration de la visualisation\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Définition des chemins vers les fichiers sources\n",
    "chemin_base = Path().resolve().parent.parent if 'notebooks' in str(Path().resolve()) else Path().resolve().parent\n",
    "dossier_donnees_intermediaires = chemin_base / \"donnees\" / \"intermediaires\"\n",
    "dossier_donnees_transformees = chemin_base / \"donnees\" / \"transformees\"\n",
    "\n",
    "# Affichage des chemins\n",
    "print(f\"Dossier des données intermédiaires: {dossier_donnees_intermediaires}\")\n",
    "print(f\"Dossier des données transformées: {dossier_donnees_transformees}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données extraites\n",
    "print(\"Chargement des données extraites...\")\n",
    "\n",
    "donnees = {}\n",
    "\n",
    "try:\n",
    "    # Chargement des données COVID-19\n",
    "    fichier_covid19 = dossier_donnees_intermediaires / \"covid19_extrait.csv\"\n",
    "    if fichier_covid19.exists():\n",
    "        donnees[\"covid19\"] = pd.read_csv(fichier_covid19)\n",
    "        print(f\"Données COVID-19 chargées: {donnees['covid19'].shape[0]} lignes, {donnees['covid19'].shape[1]} colonnes\")\n",
    "    else:\n",
    "        print(f\"Impossible de charger les données COVID-19: fichier non trouvé\")\n",
    "    \n",
    "    # Chargement des données MPOX\n",
    "    fichier_mpox = dossier_donnees_intermediaires / \"mpox_extrait.csv\"\n",
    "    if fichier_mpox.exists():\n",
    "        donnees[\"mpox\"] = pd.read_csv(fichier_mpox)\n",
    "        print(f\"Données MPOX chargées: {donnees['mpox'].shape[0]} lignes, {donnees['mpox'].shape[1]} colonnes\")\n",
    "    else:\n",
    "        print(f\"Impossible de charger les données MPOX: fichier non trouvé\")\n",
    "    \n",
    "    # Chargement des données Worldometer\n",
    "    fichier_worldometer = dossier_donnees_intermediaires / \"worldometer_extrait.csv\"\n",
    "    if fichier_worldometer.exists():\n",
    "        donnees[\"worldometer\"] = pd.read_csv(fichier_worldometer)\n",
    "        print(f\"Données Worldometer chargées: {donnees['worldometer'].shape[0]} lignes, {donnees['worldometer'].shape[1]} colonnes\")\n",
    "    else:\n",
    "        print(f\"Impossible de charger les données Worldometer: fichier non trouvé\")\n",
    "    \n",
    "    print(\"\\nChargement des données terminé avec succès!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors du chargement des données: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Nettoyage des données COVID-19\n",
    "\n",
    "Nettoyage des données COVID-19 pour les préparer à la transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des données COVID-19\n",
    "if \"covid19\" in donnees:\n",
    "    print(\"Nettoyage des données COVID-19...\")\n",
    "    \n",
    "    # Copie des données pour éviter de modifier les originales\n",
    "    covid19_clean = donnees[\"covid19\"].copy()\n",
    "    \n",
    "    # Conversion de la colonne Date en datetime\n",
    "    covid19_clean[\"Date\"] = pd.to_datetime(covid19_clean[\"Date\"])\n",
    "    \n",
    "    # Standardisation des noms de colonnes\n",
    "    covid19_clean = covid19_clean.rename(columns={\n",
    "        \"Date\": \"date\",\n",
    "        \"Country/Region\": \"pays\",\n",
    "        \"Province/State\": \"region\",\n",
    "        \"Confirmed\": \"cas_confirmes\",\n",
    "        \"Deaths\": \"deces\",\n",
    "        \"Recovered\": \"guerisons\",\n",
    "        \"Active\": \"cas_actifs\"\n",
    "    })\n",
    "    \n",
    "    # Ajout d'une colonne pour le type de pandémie\n",
    "    covid19_clean[\"type_pandemie\"] = \"COVID-19\"\n",
    "    \n",
    "    # Gestion des valeurs manquantes\n",
    "    for col in [\"cas_confirmes\", \"deces\", \"guerisons\", \"cas_actifs\"]:\n",
    "        covid19_clean[col] = covid19_clean[col].fillna(0).astype(int)\n",
    "    \n",
    "    # Affichage des informations après nettoyage\n",
    "    print(f\"Dimensions après nettoyage: {covid19_clean.shape[0]} lignes, {covid19_clean.shape[1]} colonnes\")\n",
    "    print(\"Colonnes après nettoyage:\")\n",
    "    for col in covid19_clean.columns:\n",
    "        print(f\"- {col}\")\n",
    "    print(\"\\nAperçu des données après nettoyage:\")\n",
    "    display(covid19_clean.head())\n",
    "    \n",
    "    # Vérification des valeurs manquantes après nettoyage\n",
    "    valeurs_manquantes = covid19_clean.isnull().sum()\n",
    "    print(\"\\nValeurs manquantes après nettoyage:\")\n",
    "    display(valeurs_manquantes[valeurs_manquantes > 0])\n",
    "    \n",
    "    # Sauvegarde des données nettoyées\n",
    "    donnees[\"covid19_clean\"] = covid19_clean\n",
    "    print(\"Nettoyage des données COVID-19 terminé avec succès!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Nettoyage des données MPOX\n",
    "\n",
    "Nettoyage des données MPOX pour les préparer à la transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des données MPOX\n",
    "if \"mpox\" in donnees:\n",
    "    print(\"Nettoyage des données MPOX...\")\n",
    "    \n",
    "    # Copie des données pour éviter de modifier les originales\n",
    "    mpox_clean = donnees[\"mpox\"].copy()\n",
    "    \n",
    "    # Conversion de la colonne date en datetime\n",
    "    mpox_clean[\"date\"] = pd.to_datetime(mpox_clean[\"date\"])\n",
    "    \n",
    "    # Standardisation des noms de colonnes\n",
    "    mpox_clean = mpox_clean.rename(columns={\n",
    "        \"location\": \"pays\",\n",
    "        \"total_cases\": \"cas_confirmes\",\n",
    "        \"total_deaths\": \"deces\",\n",
    "        \"new_cases\": \"nouveaux_cas\",\n",
    "        \"new_deaths\": \"nouveaux_deces\"\n",
    "    })\n",
    "    \n",
    "    # Ajout d'une colonne pour le type de pandémie\n",
    "    mpox_clean[\"type_pandemie\"] = \"MPOX\"\n",
    "    \n",
    "    # Ajout de colonnes manquantes pour uniformiser avec COVID-19\n",
    "    mpox_clean[\"region\"] = np.nan\n",
    "    mpox_clean[\"guerisons\"] = np.nan\n",
    "    mpox_clean[\"cas_actifs\"] = np.nan\n",
    "    \n",
    "    # Sélection des colonnes pertinentes\n",
    "    mpox_clean = mpox_clean[[\n",
    "        \"date\", \"pays\", \"region\", \"cas_confirmes\", \"deces\", \n",
    "        \"guerisons\", \"cas_actifs\", \"type_pandemie\"\n",
    "    ]]\n",
    "    \n",
    "    # Gestion des valeurs manquantes\n",
    "    for col in [\"cas_confirmes\", \"deces\"]:\n",
    "        mpox_clean[col] = mpox_clean[col].fillna(0)\n",
    "    \n",
    "    # Conversion des types de données\n",
    "    mpox_clean[\"cas_confirmes\"] = mpox_clean[\"cas_confirmes\"].astype(float).astype(int)\n",
    "    mpox_clean[\"deces\"] = mpox_clean[\"deces\"].astype(float).astype(int)\n",
    "    \n",
    "    # Affichage des informations après nettoyage\n",
    "    print(f\"Dimensions après nettoyage: {mpox_clean.shape[0]} lignes, {mpox_clean.shape[1]} colonnes\")\n",
    "    print(\"Colonnes après nettoyage:\")\n",
    "    for col in mpox_clean.columns:\n",
    "        print(f\"- {col}\")\n",
    "    print(\"\\nAperçu des données après nettoyage:\")\n",
    "    display(mpox_clean.head())\n",
    "    \n",
    "    # Vérification des valeurs manquantes après nettoyage\n",
    "    valeurs_manquantes = mpox_clean.isnull().sum()\n",
    "    print(\"\\nValeurs manquantes après nettoyage:\")\n",
    "    display(valeurs_manquantes[valeurs_manquantes > 0])\n",
    "    \n",
    "    # Sauvegarde des données nettoyées\n",
    "    donnees[\"mpox_clean\"] = mpox_clean\n",
    "    print(\"Nettoyage des données MPOX terminé avec succès!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Nettoyage des données Worldometer\n",
    "\n",
    "Nettoyage des données Worldometer pour les préparer à la transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyage des données Worldometer\n",
    "if \"worldometer\" in donnees:\n",
    "    print(\"Nettoyage des données Worldometer...\")\n",
    "    \n",
    "    # Copie des données pour éviter de modifier les originales\n",
    "    worldometer_clean = donnees[\"worldometer\"].copy()\n",
    "    \n",
    "    # Conversion de la colonne date en datetime\n",
    "    worldometer_clean[\"date\"] = pd.to_datetime(worldometer_clean[\"date\"])\n",
    "    \n",
    "    # Standardisation des noms de colonnes\n",
    "    worldometer_clean = worldometer_clean.rename(columns={\n",
    "        \"country\": \"pays\",\n",
    "        \"cumulative_total_cases\": \"cas_confirmes\",\n",
    "        \"cumulative_total_deaths\": \"deces\",\n",
    "        \"daily_new_cases\": \"nouveaux_cas\",\n",
    "        \"daily_new_deaths\": \"nouveaux_deces\"\n",
    "    })\n",
    "    \n",
    "    # Ajout d'une colonne pour le type de pandémie\n",
    "    worldometer_clean[\"type_pandemie\"] = \"COVID-19\"\n",
    "    \n",
    "    # Ajout de colonnes manquantes pour uniformiser avec COVID-19\n",
    "    worldometer_clean[\"region\"] = np.nan\n",
    "    worldometer_clean[\"guerisons\"] = np.nan\n",
    "    worldometer_clean[\"cas_actifs\"] = np.nan\n",
    "    \n",
    "    # Sélection des colonnes pertinentes\n",
    "    worldometer_clean = worldometer_clean[[\n",
    "        \"date\", \"pays\", \"region\", \"cas_confirmes\", \"deces\", \n",
    "        \"guerisons\", \"cas_actifs\", \"type_pandemie\"\n",
    "    ]]\n",
    "    \n",
    "    # Gestion des valeurs manquantes\n",
    "    for col in [\"cas_confirmes\", \"deces\"]:\n",
    "        worldometer_clean[col] = worldometer_clean[col].fillna(0).astype(int)\n",
    "    \n",
    "    # Affichage des informations après nettoyage\n",
    "    print(f\"Dimensions après nettoyage: {worldometer_clean.shape[0]} lignes, {worldometer_clean.shape[1]} colonnes\")\n",
    "    print(\"Colonnes après nettoyage:\")\n",
    "    for col in worldometer_clean.columns:\n",
    "        print(f\"- {col}\")\n",
    "    print(\"\\nAperçu des données après nettoyage:\")\n",
    "    display(worldometer_clean.head())\n",
    "    \n",
    "    # Vérification des valeurs manquantes après nettoyage\n",
    "    valeurs_manquantes = worldometer_clean.isnull().sum()\n",
    "    print(\"\\nValeurs manquantes après nettoyage:\")\n",
    "    display(valeurs_manquantes[valeurs_manquantes > 0])\n",
    "    \n",
    "    # Sauvegarde des données nettoyées\n",
    "    donnees[\"worldometer_clean\"] = worldometer_clean\n",
    "    print(\"Nettoyage des données Worldometer terminé avec succès!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Sauvegarde des données nettoyées\n",
    "\n",
    "Sauvegarde des données nettoyées pour l'étape suivante de transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarde des données nettoyées\n",
    "print(\"Sauvegarde des données nettoyées...\")\n",
    "\n",
    "try:\n",
    "    # Création du dossier de données transformées s'il n'existe pas\n",
    "    if not dossier_donnees_transformees.exists():\n",
    "        dossier_donnees_transformees.mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"Dossier créé: {dossier_donnees_transformees}\")\n",
    "    \n",
    "    # Sauvegarde des données COVID-19 nettoyées\n",
    "    if \"covid19_clean\" in donnees:\n",
    "        chemin_fichier = dossier_donnees_transformees / \"covid19_nettoye.csv\"\n",
    "        donnees[\"covid19_clean\"].to_csv(chemin_fichier, index=False)\n",
    "        print(f\"Données COVID-19 nettoyées sauvegardées: {chemin_fichier}\")\n",
    "    \n",
    "    # Sauvegarde des données MPOX nettoyées\n",
    "    if \"mpox_clean\" in donnees:\n",
    "        chemin_fichier = dossier_donnees_transformees / \"mpox_nettoye.csv\"\n",
    "        donnees[\"mpox_clean\"].to_csv(chemin_fichier, index=False)\n",
    "        print(f\"Données MPOX nettoyées sauvegardées: {chemin_fichier}\")\n",
    "    \n",
    "    # Sauvegarde des données Worldometer nettoyées\n",
    "    if \"worldometer_clean\" in donnees:\n",
    "        chemin_fichier = dossier_donnees_transformees / \"worldometer_nettoye.csv\"\n",
    "        donnees[\"worldometer_clean\"].to_csv(chemin_fichier, index=False)\n",
    "        print(f\"Données Worldometer nettoyées sauvegardées: {chemin_fichier}\")\n",
    "    \n",
    "    print(\"\\nSauvegarde des données nettoyées terminée avec succès!\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de la sauvegarde des données nettoyées: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Dans ce notebook, nous avons réalisé le nettoyage des données extraites pour les préparer à la transformation. Les principales opérations de nettoyage ont été :\n",
    "\n",
    "1. Conversion des dates au format datetime\n",
    "2. Standardisation des noms de colonnes\n",
    "3. Ajout d'une colonne pour le type de pandémie\n",
    "4. Gestion des valeurs manquantes\n",
    "5. Conversion des types de données\n",
    "\n",
    "Les données nettoyées ont été sauvegardées dans des fichiers CSV pour l'étape suivante de transformation : la suppression des doublons et l'agrégation des données."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
